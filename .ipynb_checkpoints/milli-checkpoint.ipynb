{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: KeysView(<HDF5 file \"TRAAAAW128F429D538.h5\" (mode r)>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'KeysView' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7aa56e9c4d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# List all groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Keys: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0ma_group_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Get the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'KeysView' object does not support indexing"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "filename = 'MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5'\n",
    "f = h5py.File(filename, 'r')\n",
    "\n",
    "# List all groups\n",
    "print(\"Keys: %s\" % f.keys())\n",
    "a_group_key = f.keys()[1]\n",
    "\n",
    "# Get the data\n",
    "data = f[a_group_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-7-9459e0f95eaf>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-9459e0f95eaf>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print data.attrs          # for example: <Attributes of HDF5 object at 230141696>\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "data # group\n",
    "\n",
    "print data.attrs          # for example: <Attributes of HDF5 object at 230141696>\n",
    "print data.attrs.keys()   # for example: ['start.seconds', 'start.nanoseconds']\n",
    "print data.attrs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e75a0191888f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TITLE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.attrs['TITLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'artist_terms', <HDF5 dataset \"artist_terms\": shape (37,), type \"|S256\">),\n",
       " (u'artist_terms_freq',\n",
       "  <HDF5 dataset \"artist_terms_freq\": shape (37,), type \"<f8\">),\n",
       " (u'artist_terms_weight',\n",
       "  <HDF5 dataset \"artist_terms_weight\": shape (37,), type \"<f8\">),\n",
       " (u'similar_artists',\n",
       "  <HDF5 dataset \"similar_artists\": shape (100,), type \"|S20\">),\n",
       " (u'songs', <HDF5 dataset \"songs\": shape (1,), type \"|V5320\">)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ ('', 165270,  0.58179377,  0.40199754, 'ARD7TVE1187B99BFB1',  nan, 'California - LA',  nan, 'e77e51a5-4761-45b3-9847-2051f811e366', 'Casual', 4479, '', 0, 0, 'Fear Itself', 300848,  0.60211999, 'SOMZWCG12A8C13C480', \"I Didn't Mean To\", 3401791)],\n",
       "      dtype=[('analyzer_version', 'S32'), ('artist_7digitalid', '<i4'), ('artist_familiarity', '<f8'), ('artist_hotttnesss', '<f8'), ('artist_id', 'S32'), ('artist_latitude', '<f8'), ('artist_location', 'S1024'), ('artist_longitude', '<f8'), ('artist_mbid', 'S40'), ('artist_name', 'S1024'), ('artist_playmeid', '<i4'), ('genre', 'S1024'), ('idx_artist_terms', '<i4'), ('idx_similar_artists', '<i4'), ('release', 'S1024'), ('release_7digitalid', '<i4'), ('song_hotttnesss', '<f8'), ('song_id', 'S32'), ('title', 'S1024'), ('track_7digitalid', '<i4')])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['songs'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hip hop', 'underground rap', 'g funk', 'alternative rap',\n",
       "       'gothic rock', 'west coast rap', 'rap', 'club dance',\n",
       "       'singer-songwriter', 'chill-out', 'underground hip hop', 'rock',\n",
       "       'gothic', 'san francisco bay area', 'indie', 'american', 'punk',\n",
       "       'california', 'industrial', 'new york', '90s', 'latin', 'spanish',\n",
       "       'dark', 'ebm', 'underground', 'deathrock', 'west coast',\n",
       "       'san francisco', 'producer', 'oakland', 'catalan', 'barcelona',\n",
       "       'doomsdope', 'norcal', 'west coast hip hop', 'alternative rock'],\n",
       "      dtype='|S256')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['artist_terms'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "b'ARD7TVE1187B99BFB1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c29731f99963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;31m# we apply this function to all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m \u001b[0mapply_to_all_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsd_subset_data_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_to_count_artist_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;31m# the most popular artist (with the most songs) is:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-c29731f99963>\u001b[0m in \u001b[0;36mapply_to_all_files\u001b[0;34m(basedir, func, ext)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# apply function to all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-c29731f99963>\u001b[0m in \u001b[0;36mfunc_to_count_artist_id\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mh5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGETTERS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_h5_file_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0martist_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGETTERS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_artist_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mfiles_per_artist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0martist_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mh5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: b'ARD7TVE1187B99BFB1'"
     ]
    }
   ],
   "source": [
    "# usual imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import sqlite3\n",
    "import tables\n",
    "\n",
    "import numpy as np # get it at: http://numpy.scipy.org/\n",
    "# path to the Million Song Dataset subset (uncompressed)\n",
    "msd_subset_path='MillionSongSubset'\n",
    "msd_subset_data_path=os.path.join(msd_subset_path,'data')\n",
    "msd_subset_addf_path=os.path.join(msd_subset_path,'AdditionalFiles')\n",
    "assert os.path.isdir(msd_subset_path),'wrong path' # sanity check\n",
    "\n",
    "\n",
    "# path to the Million Song Dataset code\n",
    "msd_code_path='MSongsDB'\n",
    "assert os.path.isdir(msd_code_path),'wrong path' # sanity check\n",
    "\n",
    "\n",
    "# we add some paths to python so we can import MSD code\n",
    "sys.path.append( os.path.join(msd_code_path,'PythonSrc') )\n",
    "\n",
    "# imports specific to the MSD\n",
    "import hdf5_getters as GETTERS\n",
    "\n",
    "# the following function simply gives us a nice string for\n",
    "# a time lag in seconds\n",
    "def strtimedelta(starttime,stoptime):\n",
    "    return str(datetime.timedelta(seconds=stoptime-starttime))\n",
    "\n",
    "# we define this very useful function to iterate the files\n",
    "def apply_to_all_files(basedir,func=lambda x: x,ext='.h5'):\n",
    "    \"\"\"\n",
    "    From a base directory, go through all subdirectories,\n",
    "    find all files with the given extension, apply the\n",
    "    given function 'func' to all of them.\n",
    "    If no 'func' is passed, we do nothing except counting.\n",
    "    INPUT\n",
    "       basedir  - base directory of the dataset\n",
    "       func     - function to apply to all filenames\n",
    "       ext      - extension, .h5 by default\n",
    "    RETURN\n",
    "       number of files\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    # iterate over all files in all subdirectories\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        # count files\n",
    "        cnt += len(files)\n",
    "        # apply function to all files\n",
    "        for f in files :\n",
    "            func(f)       \n",
    "    return cnt\n",
    "\n",
    "# # we can now easily count the number of files in the dataset\n",
    "# print 'number of song files:',apply_to_all_files(msd_subset_data_path)\n",
    "\n",
    "# let's now get all artist names in a set(). One nice property:\n",
    "# if we enter many times the same artist, only one will be kept.\n",
    "all_artist_names = set()\n",
    "\n",
    "# we define the function to apply to all files\n",
    "def func_to_get_artist_name(filename):\n",
    "    \"\"\"\n",
    "    This function does 3 simple things:\n",
    "    - open the song file\n",
    "    - get artist ID and put it\n",
    "    - close the file\n",
    "    \"\"\"\n",
    "    h5 = GETTERS.open_h5_file_read(filename)\n",
    "    artist_name = GETTERS.get_artist_name(h5)\n",
    "    all_artist_names.add( artist_name )\n",
    "    h5.close()\n",
    "    \n",
    "# let's apply the previous function to all files\n",
    "# we'll also measure how long it takes\n",
    "# t1 = time.time()\n",
    "# apply_to_all_files(msd_subset_data_path,func=func_to_get_artist_name)\n",
    "# t2 = time.time()\n",
    "# print 'all artist names extracted in:',strtimedelta(t1,t2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# let's see some of the content of 'all_artist_names'\n",
    "# print 'found',len(all_artist_names),'unique artist names'\n",
    "# for k in range(5):\n",
    "#     print list(all_artist_names)[k]\n",
    "\n",
    "# this is too long, and the work of listing artist names has already\n",
    "# been done. Let's redo the same task using an SQLite database.\n",
    "# We connect to the provided database: track_metadata.db\n",
    "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
    "                                    'subset_track_metadata.db'))\n",
    "# we build the SQL query\n",
    "q = \"SELECT DISTINCT artist_name FROM songs\"\n",
    "# we query the database\n",
    "t1 = time.time()\n",
    "res = conn.execute(q)\n",
    "all_artist_names_sqlite = res.fetchall()\n",
    "t2 = time.time()\n",
    "# print 'all artist names extracted (SQLite) in:',strtimedelta(t1,t2)\n",
    "# we close the connection to the database\n",
    "conn.close()\n",
    "# let's see some of the content\n",
    "# for k in range(5):\n",
    "#     print all_artist_names_sqlite[k][0]\n",
    "\n",
    "# now, let's find the artist that has the most songs in the dataset\n",
    "# what we want to work with is artist ID, not artist names. Some artists\n",
    "# have many names, usually because the song is \"featuring someone else\"\n",
    "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
    "                                    'subset_track_metadata.db'))\n",
    "q = \"SELECT DISTINCT artist_id FROM songs\"\n",
    "res = conn.execute(q)\n",
    "all_artist_ids = map(lambda x: x[0], res.fetchall())\n",
    "conn.close()\n",
    "\n",
    "# The Echo Nest artist id look like:\n",
    "# for k in range(4):\n",
    "#     print all_artist_ids[k]\n",
    "\n",
    "# let's count the songs from each of these artists.\n",
    "# We will do it first by iterating over the dataset.\n",
    "# we prepare a dictionary to count files\n",
    "files_per_artist = {}\n",
    "for aid in all_artist_ids:\n",
    "    files_per_artist[aid] = 0\n",
    "\n",
    "# we prepare the function to check artist id in each file\n",
    "def func_to_count_artist_id(filename):\n",
    "    \"\"\"\n",
    "    This function does 3 simple things:\n",
    "    - open the song file\n",
    "    - get artist ID and put it\n",
    "    - close the file\n",
    "    \"\"\"\n",
    "    h5 = GETTERS.open_h5_file_read(filename)\n",
    "    artist_id = GETTERS.get_artist_id(h5)\n",
    "    files_per_artist[artist_id] += 1\n",
    "    h5.close()\n",
    "\n",
    "# we apply this function to all files\n",
    "apply_to_all_files(msd_subset_data_path,func=func_to_count_artist_id)\n",
    "\n",
    "# the most popular artist (with the most songs) is:\n",
    "most_pop_aid = sorted(files_per_artist,\n",
    "                      key=files_per_artist.__getitem__,\n",
    "                      reverse=True)[0]\n",
    "# print most_pop_aid,'has',files_per_artist[most_pop_aid],'songs.'\n",
    "\n",
    "# of course, it is more fun to have the name(s) of this artist\n",
    "# let's get it using SQLite\n",
    "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
    "                                    'subset_track_metadata.db'))\n",
    "q = \"SELECT DISTINCT artist_name FROM songs\"\n",
    "q += \" WHERE artist_id='\"+most_pop_aid+\"'\"\n",
    "res = conn.execute(q)\n",
    "pop_artist_names = map(lambda x: x[0], res.fetchall())\n",
    "conn.close()\n",
    "# print 'SQL query:',q\n",
    "# print 'name(s) of the most popular artist:',pop_artist_names\n",
    "\n",
    "# let's redo all this work in SQLite in a few seconds\n",
    "t1 = time.time()\n",
    "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
    "                                    'subset_track_metadata.db'))\n",
    "q = \"SELECT DISTINCT artist_id,artist_name,Count(track_id) FROM songs\"\n",
    "q += \" GROUP BY artist_id\"\n",
    "res = conn.execute(q)\n",
    "pop_artists = res.fetchall()\n",
    "conn.close()\n",
    "t2 = time.time()\n",
    "# print 'found most popular artist in',strtimedelta(t1,t2)\n",
    "# print sorted(pop_artists,key=lambda x:x[2],reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "msd_subset_path='MillionSongSubset'\n",
    "msd_subset_data_path=os.path.join(msd_subset_path,'data')\n",
    "msd_subset_addf_path=os.path.join(msd_subset_path,'AdditionalFiles')\n",
    "assert os.path.isdir(msd_subset_path),'wrong path' # sanity check\n",
    "\n",
    "\n",
    "# path to the Million Song Dataset code\n",
    "msd_code_path='MSongsDB'\n",
    "assert os.path.isdir(msd_code_path),'wrong path' # sanity check\n",
    "\n",
    "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
    "                                    'subset_track_metadata.db'))\n",
    "# q = \"SELECT DISTINCT artist_id,artist_name,Count(track_id) FROM songs\"\n",
    "q = \"SELECT title, artist_name FROM songs\"\n",
    "# q += \" GROUP BY artist_id\"\n",
    "res = conn.execute(q)\n",
    "all_artist_names_sqlite  = res.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "all_songs = pd.read_sql_query(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Sébastien Roch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-start ID-</td>\n",
       "      <td>The Mad Capsule Markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'57 Chevrolet</td>\n",
       "      <td>Billie Jo Spears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Round the Wheel</td>\n",
       "      <td>DJ Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Ti Monde (LP Version)</td>\n",
       "      <td>BeauSoleil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title              artist_name\n",
       "0                                   Sébastien Roch\n",
       "1              -start ID-  The Mad Capsule Markets\n",
       "2           '57 Chevrolet         Billie Jo Spears\n",
       "3        'Round the Wheel                 DJ Harry\n",
       "4  'Ti Monde (LP Version)               BeauSoleil"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import requests\n",
    "def load_secrets():\n",
    "    '''Load Spotify Client ID and Client Secret from \"~/.secrets/spotify_api.yaml\" '''\n",
    "    secret_file = os.path.join(os.environ['HOME'], '.secrets/spotify_api.yaml')\n",
    "    with open(secret_file) as f:\n",
    "        secrets = yaml.load(f)\n",
    "    return secrets\n",
    "\n",
    "def get_token(secrets):\n",
    "    \"\"\"Get an access token for the Spotify API.\"\"\"\n",
    "    url = \"https://accounts.spotify.com/api/token\"\n",
    "    payload = secrets.copy()\n",
    "    payload['grant_type'] = 'client_credentials'\n",
    "    \n",
    "    r = requests.post(url, data=payload)\n",
    "    return r.json()\n",
    "\n",
    "def spotify_request(url, token, params):\n",
    "    \"\"\"Make a Spotify request using the specified token and parameters.\"\"\"\n",
    "    r = requests.get(url, headers={'Authorization': 'Bearer {}'.format(token['access_token'])},\n",
    "                     params=params)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "secrets = load_secrets()\n",
    "token = get_token(secrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# search for a track\n",
    "def track_id(track, artist):\n",
    "    r = requests.get(\"https://api.spotify.com/v1/search?q=track:{0}%20artist:{1}&type=track\".format(track, artist), \n",
    "                     headers={'Authorization': 'Bearer {}'.format(token['access_token'])})\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop missing rows\n",
    "all_songs.replace(r'', np.nan, regex=True, inplace=True)\n",
    "all_songs.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song = []\n",
    "for index, row in all_songs[:100].iterrows():\n",
    "    song.append((row[0], row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-startID-\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "for row in song[:1]:\n",
    "\n",
    "    track = \"\".join([letter for letter in row[0] if letter in string.ascii_letters \n",
    "                                                                    or letter in string.punctuation \n",
    "                                                                    or letter in string.digits])\n",
    "#     track =  urllib.quote_plus(\"\".join([letter for letter in row[0] if letter in string.ascii_letters \n",
    "#                                                                     or letter in string.punctuation \n",
    "#                                                                     or letter in string.digits]))\n",
    "#     artist =  urllib.quote_plus(\"\".join([letter for letter in row[1] if letter in string.ascii_letters \n",
    "#                                                                      or letter in string.punctuation \n",
    "#                                                                      or letter in string.digits]))\n",
    "# #     print track_id(track, artist)\n",
    "    print track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not a valid non-string sequence or mapping object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Users/juliecreamer/anaconda/envs/py36/lib/python3.6/urllib/parse.py\u001b[0m in \u001b[0;36murlencode\u001b[0;34m(query, doseq, safe, encoding, errors, quote_via)\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m             \u001b[0;31m# Zero-length sequences of all types will get here and succeed,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-50105df644e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0murlencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-start ID-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/juliecreamer/anaconda/envs/py36/lib/python3.6/urllib/parse.py\u001b[0m in \u001b[0;36murlencode\u001b[0;34m(query, doseq, safe, encoding, errors, quote_via)\u001b[0m\n\u001b[1;32m    848\u001b[0m             \u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             raise TypeError(\"not a valid non-string sequence \"\n\u001b[0;32m--> 850\u001b[0;31m                             \"or mapping object\").with_traceback(tb)\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliecreamer/anaconda/envs/py36/lib/python3.6/urllib/parse.py\u001b[0m in \u001b[0;36murlencode\u001b[0;34m(query, doseq, safe, encoding, errors, quote_via)\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;31m# non-empty strings will fail this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m             \u001b[0;31m# Zero-length sequences of all types will get here and succeed,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0;31m# but that's a minor nit.  Since the original implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: not a valid non-string sequence or mapping object"
     ]
    }
   ],
   "source": [
    "urlencode('-start ID-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = urllib.parse.urlencode({'https://api.spotify.com/v1/search?q':'track:{0} artist:{1}'.format('bounce back','big sean'), 'type': 'track'})\n",
    "data = data.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'https%3A%2F%2Fapi.spotify.com%2Fv1%2Fsearch%3Fq=track%3Abounce+back+artist%3Abig+sean&type=track'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_artist = []\n",
    "for row in song[:100]:\n",
    "    track_artist.append((quote(row[0]), quote(row[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('%20-start%20ID-', 'The%20Mad%20Capsule%20Markets'),\n",
       " ('%2757%20Chevrolet', 'Billie%20Jo%20Spears'),\n",
       " ('%27Round%20the%20Wheel', 'DJ%20Harry'),\n",
       " ('%27Ti%20Monde%20%28LP%20Version%29', 'BeauSoleil'),\n",
       " ('%28%20Gone%20With%20the%20Wind%29%20Bonnies%20Fatal%20Pony%20Ride',\n",
       "  'Max%20Steiner'),\n",
       " ('%28Bloody%20Paw%20On%20The%29%20Kill%20Floor', 'Busdriver'),\n",
       " ('%28Coffee%27s%20For%20Closers%29', 'Fall%20Out%20Boy'),\n",
       " ('%28Coming%20With%29%20Loving%20on%20My%20Mind', 'Tony%20Mathews'),\n",
       " ('%28Do%29Minion', 'Eluveitie'),\n",
       " ('%28Et%20puis%29%20Elle%20allait', 'La%20Berg%C3%A8re'),\n",
       " ('%28Everybody%27s%20Waiting%20For%29%20The%20Man%20With%20the%20Bag',\n",
       "  'Mannheim%20Steamroller'),\n",
       " ('%28I%20Heard%20That%29%20Lonesome%20Whistle', 'Bobby%20Darin'),\n",
       " ('%28I%20Used%20To%20Couldn%27t%20Dance%29%20Tight%20Pants',\n",
       "  'Eagles%20Of%20Death%20Metal'),\n",
       " ('%28I%20Wanna%29%20Play%20A%20Little%20While', 'J.B.Lenoir'),\n",
       " ('%28I%27m%20So%29%20Afraid%20Of%20Losing%20You%20Again', 'Charley%20Pride'),\n",
       " ('%28Prayer%20Is%20The%20Key%20To%20Heaven%29%20Faith%20Unlocks%20The%20Door',\n",
       "  'Don%20Gibson'),\n",
       " ('%28Sittin%27%29%20Alone%20At%20A%20Table%20For%20Two', 'Hank%20Locklin'),\n",
       " ('%28The%20Best%20Part%20Of%29%20Breakin%27%20Up', 'The%20Ronettes'),\n",
       " ('%28The%20Grave%20Prelude%29', 'Mobb%20Deep'),\n",
       " ('%28This%20Is%20Not%20A%29%20Love%20Song%20%28Live%29',\n",
       "  'Public%20Image%20Ltd'),\n",
       " ('%28Wake%20Up%29%20Time%20to%20Die', 'Lizzy%20Borden'),\n",
       " ('%28We%20Don%27t%20Need%20This%29%20Fascist%20Groove%20Thang',\n",
       "  'Heaven%2017'),\n",
       " ('%28We%20Don%27t%20Need%20This%29%20Fascist%20Groove%20Thang%20%28Rapino%20Club%20Mix%29',\n",
       "  'Heaven%2017'),\n",
       " ('%28You%27re%29%20Timeless%20To%20Me%20%28%22Hairspray%22%29',\n",
       "  'John%20Travolta%20/%20Christopher%20Walken'),\n",
       " ('%28eskomolto%29', 'Pagan%20Wanderer%20Lu'),\n",
       " ('...And%20He%20Loves%20It', 'The%20Kitchen'),\n",
       " ('...and%20Heavens%20Cried%20Blood', 'Swallow%20The%20Sun'),\n",
       " ('000GrandPno', 'Pumpkin%20Buzzard'),\n",
       " ('02%27-15%27', 'Karlheinz%20Stockhausen'),\n",
       " ('1%20-%20800%20-%20Quiereme%20-%20Remix', 'Luisito%20Rosario'),\n",
       " ('1.%20Allegro',\n",
       "  'Eduardo%20Fernandez%20/%20Norbert%20Blume%20/%20English%20Chamber%20Orchestra%20/%20George%20Malcolm'),\n",
       " ('1.%20Molto%20allegro%20con%20fuoco',\n",
       "  'Jean-Yves%20Thibaudet%20/%20Gewandhausorchester%20Leipzig%20/%20Herbert%20Blomstedt'),\n",
       " ('10%20%24%20Bill', 'Les%20Hurlements%20D%27leo'),\n",
       " ('100%20Club%201996%20%27%27We%20Love%20You%20Beatles%27%27%20-%20Live',\n",
       "  'Sex%20Pistols'),\n",
       " ('100%20Ways%20%28%20LP%20Version%20%29', 'Porno%20For%20Pyros'),\n",
       " ('100%25', 'Cocoa%20Tea'),\n",
       " ('100%25%20Dundee', 'The%20Roots'),\n",
       " ('1000%20Good%20Intentions', 'Rise%20Against'),\n",
       " ('1000%20Of%20Years%20Ago', 'Namatjira'),\n",
       " ('10000%20Km', 'La%20Portuaria'),\n",
       " ('1001%20Robots', 'Marco%20Beltrami'),\n",
       " ('11th%20Street', 'Open%20Hand'),\n",
       " ('12%20Seasons%20of%20Love', 'The%20Cosmosamatics'),\n",
       " ('124', 'Photek'),\n",
       " ('124%20Stomp', 'Azukx'),\n",
       " ('13%20De%20Mayo', 'Isabel%20Pantoja'),\n",
       " ('13%20jours%20en%20France', 'Francis%20Lai'),\n",
       " ('14%20Botellas', '2%20Minutos'),\n",
       " ('1492', 'Scarlet%27s%20Remains'),\n",
       " ('15%20Minutes%20Older', 'Sasha'),\n",
       " ('15%20Step', 'Radiohead'),\n",
       " ('15%C2%BA%20Off%20Cool%20%28Album%20Version%29', 'Bill%20Engvall'),\n",
       " ('16%20MM%20Dream', 'Jeremy%20Fisher'),\n",
       " ('18%20Carat%20Garbage', 'Billie%20Ray%20Martin%20Feat.%20Ann%20Peebles'),\n",
       " ('18%20De%20Noviembre', 'Maracaibo%2015'),\n",
       " ('1900%27s%20Madness%20%231', 'Ennio%20Morricone'),\n",
       " ('1969', 'Iggy%20And%20The%20Stooges'),\n",
       " ('197666%20w/%20Special%20Guest%20The%20Confederate%20Crusader%20%28Album%20Version%29',\n",
       "  'Wednesday%2013%27s%20Frankenstein%20Drag%20Queens%20From%20Planet%2013'),\n",
       " ('1987', '2%20Minutos'),\n",
       " ('19th%20Nervous%20Breakdown', 'Jason%20%26%20The%20Scorchers'),\n",
       " ('1er%20Gaou', 'Magic%20Systeme'),\n",
       " ('1st%20World%20Hypocrisy', 'Brainchoke'),\n",
       " ('2%20%2B%202%20%3D%205', 'Radiohead'),\n",
       " ('2%20Fists%20Full%20Of%20Nothing', 'Bruisers'),\n",
       " ('2%20Glocks', 'Bone%20Thugs-N-Harmony'),\n",
       " ('2%20Late%204%20Goodbyes', 'Jeff%20Scott%20Soto'),\n",
       " ('2%20Minutos', '2%20Minutos'),\n",
       " ('2%20People', 'Ann%20Lee'),\n",
       " ('2.000%20Kilometros', 'David%20Summers'),\n",
       " ('20%20horas%20de%20nada', 'Alex%20Ubago'),\n",
       " ('20.000%20Seconds', 'K%27s%20Choice'),\n",
       " ('2190%20Dias%20Contigo', 'Sven%20Tasnadi'),\n",
       " ('21st%20Century%20Time%20Bomb', 'Opiate%20For%20The%20Masses'),\n",
       " ('22%20%28Acoustic%29', 'Lily%20Allen'),\n",
       " ('22%20%28Vingt%20Deux%29%20%28Feat.%20Ours%29',\n",
       "  'Lily%20Allen%20Featuring%20Ours'),\n",
       " ('22%20Going%20On%2023', 'Butthole%20Surfers'),\n",
       " ('24%20Hours%20from%20Tulsa%20%28Bonus%20Track%29', 'Claire%20Hamill'),\n",
       " ('24.000%20Baci', 'Christos%20Dantis'),\n",
       " ('25%20Variations%20And%20Fugue%20On%20A%20Theme%20By%20G.F.%20Handel%20For%20Piano_%20Op.%2024%3A%20Aria',\n",
       "  'Solomon'),\n",
       " ('25%20Variations%20And%20Fugue%20On%20A%20Theme%20By%20G.F.%20Handel%20For%20Piano_%20Op.%2024%3A%20Fugue',\n",
       "  'Solomon'),\n",
       " ('25%20Variations%20And%20Fugue%20On%20A%20Theme%20By%20G.F.%20Handel%20For%20Piano_%20Op.%2024%3A%20Variation%20XVII',\n",
       "  'Solomon'),\n",
       " ('25%20Variations%20And%20Fugue%20On%20A%20Theme%20By%20G.F.%20Handel%20For%20Piano_%20Op.%2024%3A%20Variation%20XXII',\n",
       "  'Solomon'),\n",
       " ('2HB%20%281999%20Digital%20Remaster%29', 'Bryan%20Ferry'),\n",
       " ('2StepN', 'North%20Mississippi%20Allstars'),\n",
       " ('3', 'Britney%20Spears'),\n",
       " ('3', 'DJ%20X-Change'),\n",
       " ('3%20%2B%203', 'Vangelis'),\n",
       " ('3%20Deuces', 'Marcus%20Miller'),\n",
       " ('3%20Spirit', 'Corderoy%20%26%20U4IC%20DJ%27S'),\n",
       " ('30%20Days%20In%20The%20Hole%20%28Live%29', 'Humble%20Pie'),\n",
       " ('30%20Grad', 'Pyranja'),\n",
       " ('31%20-%2040', 'Danny%20Diablo%20feat.%20Puerto%20Rican%20Myke'),\n",
       " ('317%20East%2032nd', 'Lennie%20Tristano'),\n",
       " ('32%20Lines%20%28Album%20Version%29', 'Sophie%20B.%20Hawkins'),\n",
       " ('34%20Blues', 'Charlie%20Patton'),\n",
       " ('36%20Grad%20%28Paul%20van%20Dyk%27s%20Vandit%20Clubmix%29', '2raumwohnung'),\n",
       " ('4%20In%20The%20Morning', 'Gwen%20Stefani'),\n",
       " ('4%20Minutes%20%5BFeaturing%20Justin%20Timberlake%20And%20Timbaland%5D%20%5BJunkie%20XL%20Remix%20Edit%5D',\n",
       "  'Madonna'),\n",
       " ('4%20Minutes%20%5BFeaturing%20Justin%20Timberlake%20and%20Timbaland%5D%20%5BBob%20Sinclar%20Space%20Funk%20Remix%5D',\n",
       "  'Madonna'),\n",
       " ('4%20Sea%20Interludes%20Op.%2033a%3A%20Storm', 'Sir%20Neville%20Marriner')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
